# CSC461 - Machine Learning (Fall 2023)
# Description
How do computer programs learn to read handwritten text directly from pictures? to recognize speech on mobile devices? or to automatically detect credit card fraud? Machine Learning is an exciting and fast-moving field that studies the theoretical and methodological aspects underlying computer programs that can learn from data or past experience. CSC 461: Machine Learning surveys a mixture of mathematical foundations, traditional and newly developed machine learning algorithms, and best practices in the application of machine learning to solve real-world problems. The goal is to enable students to understand and use machine learning methods across a wide range of settings. Prerequisites: CSC 310 and MTH 215.

# Course Info
**Instructor**: Christian Esteves  
**TAs**: Guanhua Wu, Calvin Higgins  
**Lectures**: Monday & Wednesday 3:00 - 4:15 @ Bliss 290    
**EdStem**: https://edstem.org/us/join/m3qBys  
**Gradescope Entry Code**: K36B5K

# Office Hours
**Christian**: By Appointment  
**Guanhua**: T/Th 10:00am - 12:00pm [Via Zoom](https://uri-edu.zoom.us/j/8338647306)  
**Calvin**: T/Th 8:00 - 9:00am & 1:00 - 2:00pm  Tyler Floor 0 Lobby

# Recommended Textbooks
- [A Course in Machine Learning](http://ciml.info/), Hal Daumee III
- [Machine Learning: a Probabilistic Perspective](https://probml.github.io/pml-book/), K. P. Murphy
- [Machine Learning: The Art and Science of Algorithms that Make Sense of Data](http://people.cs.bris.ac.uk/~flach/mlbook//), P. Flach
- [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/), C. Bishop
- [Learning From Data](https://amlbook.com/), Y. S. Abu-Mostafa, M. Magdon-Ismail, H. T. Lin

# Additional Resources
View the collection provided by [Marco Alvarez](https://homepage.cs.uri.edu/~malvarez/teaching/csc-461/resources/#quick-reference-tools-and-visualizations)

# Homework Assignments
Homework assignments are individual work, unless stated otherwise in the assignment's instructions. Students will have roughly 7-10 days to work on each assignment. Each assignment has a specific due date/time listed on the course website. Late submissions will not be accepted. Students are strongly encouraged to bring their code or solutions to instructor's office hours prior to the due date.

# Exams
A midterm examination will be held in-person using regular lecture hours. The exam will be individual and open-book, meaning that you are free to use any printed materials during the exam. No electronic devices are allowed. Make-up exams for students are given only in rare cases of well-documented events.

# Technical Presentation
A technical presentation will be prepared by teams of two students. Exceptions may be granted with written permission from instructor (via Ed). The instructor will provide a list of topics and teams will be allowed to make their choice. The goal of each team is to become experts in their chosen topic and prepare a presentation to the class. A maximum of 25 minutes will be given to students for their presentations during the last two weeks of the semester. The deliverable is a set of slides in PDF format related to the topic of your choice.

# Final Project
The Final Project is to be done in groups of two or three students and the deliverables include: progress report, final report, and a live presentation. Your group will select a project from a list shared by the instructors. Most of the projects will require auxiliary reading and continuous effort throughout the semester. A good amount of extra-credit will be assigned to outstanding projects. A Workshop at the end of the semester will be organized for showcasing your projects and results.

# Grading
| Assessment Type | Qty. | Weight |
| ----- | ----- | ----- |
| Homeworks | ~6 | 25% |
| Midterm Exam | 1 | 25% |
| Presentation | 1 | 20% |
| Final Project | 1 | 30% |

# Academic Honesty
Discussions with peers to gain more insights on coursework and lectures is strongly encouraged. However, when working on assignments, **all written work and source code must be original**. Students might not look at anyone's written solution. **Copying another individual solution is plagiarism**, a serious offense, and the one most common in computer science courses. Anyone that provides homework answers or source code for a programming assignment to another individual is also guilty of academic dishonesty. Students caught plagiarizing will be prosecuted in accordance with the [University's Academic Honesty Procedures](https://web.uri.edu/studentconduct/academic-honesty-procedures/).

# Disability Accommodations
Any student with a documented disability is welcome to contact me as early in the semester as possible, so that we may arrange reasonable accommodations. As part of this process, please be in touch with [Disability, Access, and Inclusion Office](https://web.uri.edu/disability/).

# Tentative Schedule
| Topic | Required Reading | Materials |
| --- | --- | --- |
| Introduction to CSC 461 | [Google's Python Class](https://developers.google.com/edu/python) <br /> [Linear Algebra Lecture](https://drive.google.com/file/d/1-RPRNpP6W7FqOzPGFIvGV4etObCeGmF0/view?usp=sharing) | [Lecture Slides](https://drive.google.com/file/d/1g_mvToKs2CYN8CFVlwkfslnqPPx2YvQu/view?usp=sharing) <br /> [Colab Notebook](https://drive.google.com/file/d/1S-2Q8D8iMjd8ZFzyq-kpqFdrHqI5A14l/view?usp=sharing)  |
| Introduction to Machine Learning  | [Python NumPy Tutorial](https://cs231n.github.io/python-numpy-tutorial/) | [Lecture Slides](https://drive.google.com/file/d/1t9_2rs8xp-csEMPv14AgYYN3erCJZKx6/view?usp=sharing) |
| Unsupervised Learning, Clustering, K-Means | [Section 22.2 from UML](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/copy.html) | [Lecture Slides](https://drive.google.com/file/d/1qbVglkA0bVjs1wQI-E5mWFyJsWFLwezn/view?usp=sharing) <br /> [Colab Notebook](https://drive.google.com/file/d/1jQaeKI4Cna-wytnDtM3uqRX7ObzXbfzz/view?usp=sharing) |
| Hierarchical Clustering | [Section 12.4 from ISL](https://www.statlearning.com/) | [Lecture Slides](https://drive.google.com/file/d/1I8OBK2CoUSRqxQ11-fkbxjIsg0NYIN55/view?usp=sharing) |
| Principal Component Analysis | [Section 12.1 from PRML](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/) | [Lecture Slides](https://drive.google.com/file/d/1fdWfTHkOsw-aAKw46VsLAlitk7j8Wxiy/view?usp=share_link) <br /> [Colab Notebook](https://drive.google.com/file/d/1UT7H78WKfWGunrYmbJx4a5ejzc7xUewi/view?usp=sharing) |
| Introduction to Supervised Learning | [Cornell Lecture Notes](https://www.cs.cornell.edu/courses/cs4780/2021fa/lectures/lecturenote01_MLsetup.html) | [Lecture Slides](https://drive.google.com/file/d/1ikVSPhWUfJ6SXQDb_TNQDDEAAo5m4kZM/view?usp=sharing) <br /> [Colab Notebook](https://drive.google.com/file/d/1g_sORqwHy9w2JPrCFdfiCx6kvIGrdynu/view?usp=sharing) |
| Linear Regression | [Stanford's CS229 Lecture Notes](https://drive.google.com/file/d/1jlZ7jSb4TqmifBumvEDwF9EwoN80xFQ3/view?usp=sharing) | [Lecture Notes](https://drive.google.com/file/d/1VcpPlPVQ-KrfigS1K32VktCe-OSxj1dT/view?usp=sharing) <br /> [Colab Notebook](https://drive.google.com/file/d/1ffjO8LTmDbYfChoT6jJyJpUu1d2eXubI/view?usp=sharing) |
| Nonlinear Features, Overfitting, Regularization, Model Selection | [Section 1.1 from PRML](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/) <br /> [Practical Issues](http://ciml.info/dl/v0_99/ciml-v0_99-ch05.pdf) | [Lecture Notes](https://drive.google.com/file/d/1IZSe4Z0GFEwHubDWzAVb-mA1c3TYmEPV/view?usp=sharing) <br /> [Colab Notebook](https://drive.google.com/file/d/1nhLaTrSpO4K-tNlZhjo64B7TBv53qld7/view?usp=sharing) |
| Gradient Descent | [Chapter 6 from IDA](https://www.cs.utah.edu/~jeffp/IDABook/T6-GD.pdf) | [Lecture Notes](https://drive.google.com/file/d/1OPGb91EyYf9HgIwhtob-QfXO0bdJbPJ_/view?usp=sharing) <br /> [Colab Notebook](https://drive.google.com/file/d/1hvyoypy8q6HrN1DQvrKde3ZD6mk65wn2/view?usp=sharing) |
| Gradient Descent ML | | [Lecture Notes](https://drive.google.com/file/d/1stuKXJy1jUFqFIZs3T9IEeNQJkRZnnsC/view?usp=sharing) <br /> [Colab Notebook](https://drive.google.com/file/d/1SI2xk8lzCP9BJKCT_MS4RPoieQ8LpxA8/view?usp=sharing)
| Feedback Session |  | [Lecture Notes](https://drive.google.com/file/d/11sM4yA8xRHJfLlwio4Ua21jjr-emFajn/view?usp=sharing) |
| Linear Classifiers and Logistic Regression | [Sections 4.1, 4.2 from PRML](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/) | [Lecture Notes](link) <br /> [Colab Notebook](link) |
| Multinomial Logistic Regression | [Section 4.3 from PRML](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/) | [Lecture Notes](link) |
| Evaluation and Model Selection, Perceptron |  | [Lecture Notes](link) |
| Multilayer Perceptrons | [Chapter 6 from DL](https://www.deeplearningbook.org/contents/mlp.html) | [Lecture Notes](link) <br /> [Colab Notebook 1](link) <br /> [Colab Notebook 2](link) |
| k-NN Classification | [Geometry and Nearest Neighbors](http://ciml.info/dl/v0_99/ciml-v0_99-ch03.pdf) | [Lecture Notes](link) |
| Decision Trees | [Decision Trees](http://ciml.info/dl/v0_99/ciml-v0_99-ch01.pdf) | [Lecture Notes](link) |
| Bagging | [Ensemble Methods](http://ciml.info/dl/v0_99/ciml-v0_99-ch13.pdf) | [Lecture Notes](link) |
| Boosting | [Ensemble Methods](http://ciml.info/dl/v0_99/ciml-v0_99-ch13.pdf) | [Lecture Notes](link) |

# Assignments
| Assignment | Due Date | Access |
| --- | --- | --- |
| Homework 1 | 9/22 | [Colab Notebook](https://drive.google.com/file/d/1uUd6RRP3eR3s0wf8vcQfTzz45jwFwvKn/view?usp=sharing) |
| Homework 2 | 10/8 | [Colab Notebook](https://drive.google.com/file/d/1RqhmD49GIi7ROaN9LLVD6DrdvIGLhH9D/view?usp=sharing) |
| Homework 3 | 10/25 | [Colab Notebook](https://drive.google.com/file/d/1Eyg4frK5Nx0bP98PclxCy9xsjWpahhq4/view?usp=sharing) |
| Homework 4 | TBD | [Colab Notebook]() |
| Homework 5 | TBD | [Colab Notebook]() |
| Homework 6 | TBD | [Colab Notebook]() |
